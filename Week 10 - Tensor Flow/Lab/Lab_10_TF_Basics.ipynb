{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic tensorflow: Creating a graph\n",
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right after we import TensorFlow (with import tensorflow as tf), a specific empty default graph is formed. \n",
    "All the nodes we create are automatically associated with that default graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the tf.<operator> methods, we will create six nodes assigned to arbitrarily named variables. The contents of these variables should be regarded as the output of the operations, and not the operations themselves. For now we refer to both the operations and their outputs with the names of their corresponding variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three nodes are each told to output a constant value. \n",
    "The values 5, 2, and 3 are assigned to $a,$ $b,$ and $c,$ respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(5, name = \"a\") \n",
    "b = tf.constant(2, name = \"b\")\n",
    "c = tf.constant(3, name = \"c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the next three nodes gets two existing variables as inputs, and performs simple arithmetic operations on them:\n",
    "Node $d$ multiplies the outputs of nodes $a$ and $b.$ Node $e$ adds the outputs of nodes $b$ and $c.$ Node $f$ subtracts the output of node $e$ from that of node $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = tf.multiply(a,b, name = \"op_multi\") \n",
    "e = tf.add(c,b, name = \"op_add\") \n",
    "f = tf.subtract(d,e, name = \"op_subtract\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we should get a tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "outs = sess.run([f,e,d])\n",
    "filewriter = tf.summary.FileWriter(\"output1\", sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![graph_large_attrs_key=_too_large_attrs&limit_attr_size=1024&run=.png](attachment:graph_large_attrs_key=_too_large_attrs&limit_attr_size=1024&run=.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some arithmetic and logical operations it is possible to use operation shortcuts instead of having to apply tf.<operator>. For example, in this graph we could have used $*/+/-$ instead of tf.multiply()/tf.add()/tf.subtract()\n",
    "Some shortcuts for common operations are: \n",
    "\n",
    "    tf.add()      a + b\n",
    "    tf.multiply   a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Session and running it:\n",
    "------\n",
    "Once we are done describing the computation graph, we are ready to run the computations that it represents. For this to happen, we need to create and run a session. We do this by adding the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = 5\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()  #this is an operator called a constructor that creates an object of type Session\n",
    "outs = sess.run(f) \n",
    "sess.close() \n",
    "print(\"outs = {}\".format(outs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we launch the graph in a tf.Session. A Session object is the part of the TensorFlow API that communicates between Python objects and data on our end, and the actual computational system where memory is allocated for the objects we define, intermediate variables are stored, and finally results are fetched for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution itself is then done with the .run() method of the Session object. When called, this method completes one set of computations in our graph in the following manner: it starts at the requested output(s) and then works backward, computing nodes that must be executed according to the set of dependencies. Therefore, the part of the graph that will be computed depends on our output query.\n",
    "\n",
    "In our example, we requested that node f be computed and got its value, 5, as output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs = sess.run(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When our computation task is completed, it is good practice to close the session using the sess.close() command, making sure the resources used by our session are freed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing and Managing our graph:\n",
    "======\n",
    "As mentioned, as soon as we import TensorFlow, a default graph is automatically created for us with a session. We can create additional graphs and control their association with some given operations. tf.Graph() creates a new graph, represented as a TensorFlow object. In this example we create another graph and assign it to the variable $g$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7f7d9c275210>\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f7d9c205710>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.get_default_graph())\n",
    "\n",
    "g = tf.Graph()  #this is a constructor for Graph object\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have multiple graphs in your program. \n",
    "\n",
    "At this point we have two graphs: the default graph and the empty graph in $g$. Both are revealed as TensorFlow objects when printed. Since $g$ hasn’t been assigned as the default graph, any operation we create will not be associated with it, but rather with the default one.\n",
    "\n",
    "We can check which graph is currently set as the default by using tf.get_default_graph(). Also, for a given node, we can view the graph it’s associated with by using the <node>.graph attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()  #new graph\n",
    "a = tf.constant(5)  #a is a constant, but in which graph is it? \n",
    "\n",
    "print(a.graph is g)\n",
    "print(a.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.graph is g  #can ask if a belongs to our new graph g? But it doesn't -- it belongs to the default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code example we see that the operation we’ve created is associated with the default graph and not with the graph in $g$.\n",
    "\n",
    "To make sure our constructed nodes are associated with the right graph we can construct them using a very useful Python construct: the with statement.\n",
    "\n",
    "The with statement is used to wrap the execution of a block with methods defined by a context manager—an object that has the special method functions .__enter__() to set up a block of code and .__exit__() to exit the block.\n",
    "\n",
    "In other words, it’s very convenient in many cases to execute some code that requires “setting up” of some kind (like opening a file, SQL table, etc.) and then always “tearing it down” at the end, regardless of whether the code ran well or raised any kind of exception. In our case we use with to set up a graph and make sure every piece of code will be performed in the context of that graph.\n",
    "\n",
    "We use the with statement together with the as_default() command, which returns a context manager that makes this graph the default one. This comes in handy when working with multiple graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.get_default_graph() \n",
    "g2 = tf.Graph() \n",
    "\n",
    "print(g1 is tf.get_default_graph())   # output should be True because g1 is our default graph\n",
    "\n",
    "with g2.as_default():       #with is a keyword that starts a new block or scope; it ends with an empty line\n",
    "    print(g1 is tf.get_default_graph()) #in this block of code, use g2 as the default graph #False because g1 \n",
    "                                        #is no longer default\n",
    "\n",
    "print(g1 is tf.get_default_graph())  #True because our scope ended with the empty line above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The with statement can also be used to start a session without having to explicitly close it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetches:\n",
    "===\n",
    "In our initial graph example, we request one specific node (node $f$) by passing the variable it was assigned to as an argument to the sess.run() method. This argument is called fetches, corresponding to the elements of the graph we wish to compute. We can also ask sess.run() for multiple nodes’ outputs simply by inputting a list of requested nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = [5, 2, 3, 10, 5, 5]\n",
      "<type 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "   fetches = [a,b,c,d,e,f]\n",
    "   outs = sess.run(fetches) \n",
    "\n",
    "print(\"outs = {}\".format(outs)) \n",
    "print(type(outs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get back a list containing the outputs of the nodes according to how they were ordered in the input list. The data in each item of the list is of type NumPy.\n",
    "\n",
    "TensorFlow computes only the essential nodes according to the set of dependencies. This is also manifested in our example: when we ask for the output of node $d$, only the outputs of nodes $a$ and $b$ are computed. This is a great advantage of TensorFlow—it doesn’t matter how big and complicated our graph is as a whole, since we can run just a small portion of it as needed.\n",
    "\n",
    "Opening a session using the with clause will ensure the session is automatically closed once all computations are done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flowing tensors:\n",
    "======\n",
    "Understanding how nodes and edges are actually represented in TensorFlow, and how we can control their characteristics. To demonstrate how they work, we will focus on source operations, which are used to initialize values.\n",
    "\n",
    "Nodes are operations, Edges are tensor objects\n",
    "\n",
    "When we construct a node in the graph, like we did with tf.add(), we are actually creating an operation instance. These operations do not produce actual values until the graph is executed, but rather reference their to-be-computed result as a handle that can be passed on—flow—to another node. These handles, which we can think of as the edges in our graph, are referred to as Tensor objects, and this is where the name TensorFlow originates from.\n",
    "\n",
    "TensorFlow is designed such that first a skeleton graph is created with all of its components. At this point no actual data flows in it and no computations take place. It is only upon execution, when we run the session, that data enters the graph and computations occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous example, tf.constant() created a node with the corresponding passed value. Printing the output of the constructor, we see that it’s actually a Tensor object instance. These objects have methods and attributes that control their behavior and that can be defined upon creation.\n",
    "\n",
    "In this example, the variable $c$ stores a Tensor object with the name Const 5:0, designated to contain a 32-bit floating-point scalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_9:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant(4.0)  #in python and TF, you just give the value 4.0, and TF assumes that 4.0 is float\n",
    "print(c)\n",
    "#If you wanted this to be float64, you would have to cast\n",
    "#If you run this many times, the value will increase because it has many c constants in its graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting attributes with source operations\n",
    "=====\n",
    "Each Tensor object in TensorFlow has attributes such as name, shape, and dtype that help identify and set the characteristics of that object. These attributes are optional when creating a node, and are set automatically by TensorFlow when missing. \n",
    "\n",
    "We will take a look at these attributes. We will do so by looking at Tensor objects created by ops known as source operations. Source operations are operations that create data, usually without using any previously processed inputs. With these operations we can create scalars, as we already encountered with the tf.constant() method, as well as arrays and other types of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types\n",
    "======\n",
    "The basic units of data that pass through a graph are numerical, Boolean, or string elements.  When we print out the Tensor object $c$  from our last code example, we see that its data type is a floating-point number. Since we didn’t specify the type of data, TensorFlow inferred it automatically. For example 5 is regarded as an integer, while anything with a decimal point, like 5.1, is regarded as a floating-point number.\n",
    "\n",
    "We can explicitly choose what data type we want to work with by specifying it when we create the Tensor object. We can see what type of data was set for a given Tensor object by using the attribute dtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_10:0\", shape=(), dtype=float64)\n",
      "<dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant(4.0, dtype=tf.float64)\n",
    "print(c)\n",
    "print(c.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow supports many data types. \n",
    "====\n",
    "* Complex numbers\n",
    "* Booleans\n",
    "* Strings\n",
    "* Integers\n",
    "* etc.\n",
    "\n",
    "It is important to make sure our data types match throughout the graph—performing an operation with two nonmatching data types will result in an exception. To change the data type setting of a Tensor object, we can use the tf.cast() operation, passing the relevant Tensor and the new data type of interest as the first and second arguments, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "<dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,2,3],name='x',dtype=tf.float32)  \n",
    "print(x.dtype)\n",
    "x = tf.cast(x,tf.int64) #turn the float number above into integer\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Array and Shapes:\n",
    "======\n",
    "~A source of potential confusion is that two different things are referred to by the name, Tensor. As used in the previous sections, Tensor is the name of an object used in the Python API as a handle for the result of an operation in the graph. \n",
    "\n",
    "However, tensor is also a mathematical term for n-dimensional arrays. For example, a $1×1$ tensor is a scalar, a $1×n$ tensor is a vector, an n×n tensor is a matrix, and an n×n×n tensor is just a three-dimensional array. \n",
    "\n",
    "TensorFlow regards all the data units that flow in the graph as tensors, whether they are multidimensional arrays, vectors, matrices, or scalars.\n",
    "\n",
    "As with dtype, unless stated explicitly, TensorFlow automatically infers the shape of the data. When we printed out the Tensor object at the beginning of this section, it showed that its shape was (), corresponding to the shape of a scalar.\n",
    "\n",
    "Using scalars is good for demonstration purposes, but most of the time it’s much more practical to work with multidimensional arrays. To initialize high-dimensional arrays, we can use Python lists or NumPy arrays as inputs. \n",
    "\n",
    "In the following example, we use as inputs a $2×3$ matrix using a Python list and then a 3D NumPy array of size $2×2×3$ (two matrices of size $2×3$)\n",
    "\n",
    "Note: Numpy is a useful package for numerical computing and working with arrays. Tensorflow and Numpy are tightly coupled. For example, the output returned by sess.run() is a NumPy array.  Many TF operations have the same syntax as funcions in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6]]\n",
      "<type 'list'>\n",
      "<type 'numpy.ndarray'>\n",
      "Python List input: (2, 3)\n",
      "3d NumPy array input: (2, 2, 3)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "a = [[1,2,3],\n",
    "     [4,5,6]]    # a is a matrix or a python list; you can use regular python matrices\n",
    "print (a)\n",
    "print (type (a))\n",
    "b = np.array(a)   #this is a numpy array; in your programs you can have various types of objects\n",
    "print (type(b))\n",
    "c = tf.constant([[1,2,3],     #you wanna make a tensor c; could have writte d - tf.(a); TF operation can \n",
    "                [4,5,6]])              #take numpy objects  and turn them into tensors\n",
    "                  \n",
    "print(\"Python List input: {}\".format(c.get_shape()))\n",
    "\n",
    "c = tf.constant(np.array([    #turning numpy array into tensor\n",
    "                 [[1,2,3], \n",
    "                  [4,5,6]], \n",
    "\n",
    "                 [[1,1,1], \n",
    "                  [2,2,2]]\n",
    "                 ])) \n",
    "#Another way to turn numpy array into tensor:\n",
    "print(\"3d NumPy array input: {}\".format(c.get_shape()))\n",
    "bb = tf.convert_to_tensor(b, dtype = tf.float32) #turns numpy array into a real tensor\n",
    "print (type(bb))          #you can always as for the type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_shape() method returns the shape of the tensor as a tuple of integers. The number of integers corresponds to the number of dimensions of the tensor, and each integer is the number of array entries along that dimension. For example, a shape of $(2,3)$ indicates a matrix, since it has two integers, and the size of the matrix is $2×3$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables, Placeholders:\n",
    "=======\n",
    "Variables can maintain a fixed state in the graph. This is important because their current state might influence how they change in the following iteration. Like other Tensors, Variables can be used as input for other operations in the graph.\n",
    "\n",
    "Using Variables is done in two stages. First we call the tf.Variable() function in order to create a Variable and define what value it will be initialized with. We then have to explicitly perform an initialization operation by running the session with the tf.global_variables_initializer() method, which allocates the memory for the Variable and sets its initial values.\n",
    "\n",
    "Like other Tensor objects, Variables are computed only when the model runs, as we can see in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre run: \n",
      "<tf.Variable 'var:0' shape=(1, 5) dtype=float32_ref>\n",
      "\n",
      "post run: \n",
      "[[-0.30407318 -0.92795068  0.5859226   0.45946285  2.25937557]]\n"
     ]
    }
   ],
   "source": [
    "init_val = tf.random_normal((1,5),0,1)  #random normal distribution that gives you matrix of shape 1x5 centered at 0, \n",
    "                                        #with standard dev of 1\n",
    "var = tf.Variable(init_val, name='var') #this is a constructor, it will be named Var in the graph\n",
    "print(\"pre run: \\n{}\".format(var)) #\\n is for new line\n",
    "\n",
    "init = tf.global_variables_initializer()  #init is an operation that initializes all of your variables\n",
    "#but with this line you create a node called init, which is why you have to open a session to run init\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # print (var) everything that was supposed ot be initialized was, but the variable var has not been calculated yet\n",
    "    post_var = sess.run(var)\n",
    "\n",
    "print(\"\\npost run: \\n{}\".format(post_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow has designated built-in structures for feeding input values. These structures are called placeholders. Placeholders can be thought of as empty Variables that will be filled with data later on. We use them by first constructing our graph and only when it is executed feeding them with the input data.\n",
    "\n",
    "\n",
    "Placeholders have an optional shape argument. If a shape is not fed or is passed as None, then the placeholder can be fed with data of any size. It is common to use None for the dimension of a matrix that corresponds to the number of samples (usually rows), while having the length of the features (usually columns) fixed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ph = tf.placeholder(tf.float32,shape=(None,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we define a placeholder, we must feed it with some input values or else an exception will be thrown. The input data is passed to the session.run() method as a dictionary, where each key corresponds to a placeholder variable name, and the matching values are the data values given in the form of a list or a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-d46a87107525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_data' is not defined"
     ]
    }
   ],
   "source": [
    "sess.run(s,feed_dict={x: X_data,w: w_data})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see how it looks with another graph example, this time with placeholders for two inputs: a matrix $x$ and a vector $w.$ These inputs are matrix-multiplied to create a five-unit vector $xw$ and added with a constant vector $b$ filled with the value $-1$. Finally, the variable $s$ takes the maximum value of that vector by using the tf.reduce_max() operation. The word reduce is used because we are reducing a five-unit vector to a single scalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "outs = 2.84774780273\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_data = np.random.randn(5,10) #random normal matix of shape 5x10\n",
    "w_data = np.random.randn(10,1) #vector\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x = tf.placeholder(tf.float32,shape=(5,10))  #x is placeholder for variable\n",
    "    w = tf.placeholder(tf.float32,shape=(10,1))  \n",
    "    b = tf.fill((5,1),-1.0) #matrix with one column and 5 rows filled with -1\n",
    "    xw = tf.matmul(x,w) #matmul means matrix multiply matrix x and vector w\n",
    "\n",
    "    xwb = xw + b   #a vertical vctor, product of matrix x and vector w plus vector b, which is also a vertical vector\n",
    "    s = tf.reduce_max(xwb)  #computes maximum across dimensions of a tensor\n",
    "    #up to here, this is all symbolic math -- there are no values \n",
    "    #Now we want to calculate s\n",
    "    with tf.Session() as sess:\n",
    "        outs = sess.run(s,feed_dict={x: x_data,w: w_data}) #feed dictionary (in lecture), when you have a key and its value. \n",
    "        #x is key, x_data is value\n",
    "        #Finally now, we're giving values for x and w using feed dictionary\n",
    "        print (sess.run(b))\n",
    "\n",
    "print(\"outs = {}\".format(outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
